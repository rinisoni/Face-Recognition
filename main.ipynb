{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "known_faces_folder = \"/home/hiren/Desktop/FaceRecognition/known_faces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_encodings = []\n",
    "known_face_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning file names\n",
    "def clean_name(filename):\n",
    "    name = os.path.splitext(filename)[0]  # Remove file extension\n",
    "    name = re.sub(r'\\(\\d+\\)', '', name)\n",
    "    name = re.sub(r'\\d+$', '', name)\n",
    "\n",
    "    return name.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load known faces\n",
    "for filename in os.listdir(known_faces_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "        img_path = os.path.join(known_faces_folder, filename)\n",
    "        image = face_recognition.load_image_file(img_path)\n",
    "\n",
    "        # Face encodings\n",
    "        encodings = face_recognition.face_encodings(image)\n",
    "        if encodings:\n",
    "            known_face_encodings.append(encodings[0])\n",
    "            known_face_names.append(clean_name(filename))  # Store cleaned name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occupancy and Aiva Response Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIVA: Hi rini, I am AIVA, your assistant. How can I help you?\n",
      "Occupancy: 1\n",
      "recognized_faces: 1\n",
      "unknown_faces: 0\n",
      "recognized_names: ['rini']\n",
      "timestamp: 2025-04-11 15:05:18\n",
      "\u001b[93mNOTICE: 1 recognized face(s) detected\u001b[0m\n",
      "\u001b[92mSTATUS: CLEAN - No faces detected\u001b[0m\n",
      "AIVA: Hi rini, I am AIVA, your assistant. How can I help you?\n",
      "Occupancy: 1\n",
      "recognized_faces: 1\n",
      "unknown_faces: 0\n",
      "recognized_names: ['rini']\n",
      "timestamp: 2025-04-11 15:05:32\n",
      "\u001b[93mNOTICE: 1 recognized face(s) detected\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import time\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import pygame\n",
    "import tempfile\n",
    "\n",
    "\n",
    "pygame.mixer.init()\n",
    "\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Track visitors\n",
    "current_visitors = set()  # Names currently in frame\n",
    "greeted_visitors = set()  # Names that have been greeted in this session\n",
    "last_output_time = 0\n",
    "output_interval = 5  # Minimum seconds between status outputs\n",
    "last_status = None\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Convert text to speech using female American English voice\"\"\"\n",
    "    try:\n",
    "        tts = gTTS(text=text, lang='en', tld='us', slow=False)\n",
    "        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as fp:\n",
    "            temp_filename = fp.name\n",
    "        tts.save(temp_filename)\n",
    "        pygame.mixer.music.load(temp_filename)\n",
    "        pygame.mixer.music.play()\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            pygame.time.Clock().tick(10)\n",
    "        pygame.mixer.music.unload()\n",
    "        os.unlink(temp_filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Speech synthesis error: {e}\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Process frame\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "    rgb_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "    # Detect faces\n",
    "    current_names = set()\n",
    "    new_visitors = set()\n",
    "    detected_names = []\n",
    "    unknown_faces = 0\n",
    "    \n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        name = \"Unknown\"\n",
    "        is_unknown = True\n",
    "\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "        if True in matches:\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if face_distances[best_match_index] < 0.5:\n",
    "                name = known_face_names[best_match_index]\n",
    "                is_unknown = False\n",
    "\n",
    "        if is_unknown:\n",
    "            unknown_faces += 1\n",
    "        else:\n",
    "            detected_names.append(name)\n",
    "            current_names.add(name)\n",
    "            if name not in current_visitors and name not in greeted_visitors:\n",
    "                new_visitors.add(name)\n",
    "                greeted_visitors.add(name)\n",
    "\n",
    "        # Draw on frame\n",
    "        top, right, bottom, left = top * 2, right * 2, bottom * 2, left * 2\n",
    "        color = (0, 0, 255) if is_unknown else (0, 255, 0)\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "        cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "    # Greet new visitors\n",
    "    for name in new_visitors:\n",
    "        greeting = f\"Hi {name}, I am AIVA, your assistant. How can I help you?\"\n",
    "        print(f\"AIVA: {greeting}\")\n",
    "        speak(greeting)\n",
    "\n",
    "    # Update visitor tracking\n",
    "    departed_visitors = current_visitors - current_names\n",
    "    current_visitors = current_names\n",
    "\n",
    "    # Clear greeted visitors if they leave\n",
    "    for name in departed_visitors:\n",
    "        if name in greeted_visitors:\n",
    "            greeted_visitors.remove(name)\n",
    "\n",
    "    # Print status only on significant changes\n",
    "    current_time = time.time()\n",
    "    current_status = {\n",
    "        'occupancy': len(face_locations),\n",
    "        'recognized': detected_names,\n",
    "        'unknown': unknown_faces\n",
    "    }\n",
    "\n",
    "    should_print = False\n",
    "    \n",
    "    # Print if status changed significantly\n",
    "    if current_status != last_status:\n",
    "        should_print = True\n",
    "    # Or if periodic interval passed and we have faces\n",
    "    elif len(face_locations) > 0 and current_time - last_output_time > output_interval:\n",
    "        should_print = True\n",
    "    # Or if someone just left\n",
    "    elif len(departed_visitors) > 0:\n",
    "        should_print = True\n",
    "\n",
    "    if should_print:\n",
    "        last_output_time = current_time\n",
    "        last_status = current_status\n",
    "        \n",
    "        if len(face_locations) == 0:\n",
    "            print(\"\\033[92mSTATUS: CLEAN - No faces detected\\033[0m\")\n",
    "        else:\n",
    "            print(\"Occupancy:\", len(face_locations))\n",
    "            print(\"recognized_faces:\", len(detected_names))\n",
    "            print(\"unknown_faces:\", unknown_faces)\n",
    "            print(\"recognized_names:\", detected_names if detected_names else \"None\")\n",
    "            print(\"timestamp:\", time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            \n",
    "            if unknown_faces > 0:\n",
    "                print(\"\\033[91mALERT: {} face(s) detected ({} unknown)!\\033[0m\".format(\n",
    "                    len(face_locations), unknown_faces))\n",
    "            else:\n",
    "                print(\"\\033[93mNOTICE: {} recognized face(s) detected\\033[0m\".format(len(detected_names)))\n",
    "\n",
    "    # Display frame with status\n",
    "    if len(face_locations) == 0:\n",
    "        status_text = \"Status: CLEAN - No faces detected\"\n",
    "        status_color = (0, 255, 0)\n",
    "    else:\n",
    "        status_text = f\"Status: {len(face_locations)} face(s) detected\"\n",
    "        status_color = (0, 165, 255)\n",
    "        if unknown_faces > 0:\n",
    "            status_text += f\" ({unknown_faces} unknown)\"\n",
    "\n",
    "    cv2.putText(frame, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)\n",
    "    \n",
    "    if detected_names:\n",
    "        cv2.putText(frame, \"Recognized: \" + \", \".join(detected_names), (10, 60), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    elif len(face_locations) > 0:\n",
    "        cv2.putText(frame, \"No recognized faces\", (10, 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Live Face Recognition\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proper working code of Face Recognition Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Fame resizing faster processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "    # Convert to RGB\n",
    "    rgb_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Find faces and their encodings\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "    # Process each detected face\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        name = \"Unknown\"\n",
    "        color = (0, 0, 255)  # Default to red for \"Unknown\"\n",
    "\n",
    "        # Compare with known faces\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "        # If there is at least one match\n",
    "        if True in matches:\n",
    "            best_match_index = np.argmin(face_distances)  # Get the closest match\n",
    "\n",
    "            # Set a confidence threshold (lower distance=better match)\n",
    "            if face_distances[best_match_index] < 0.5:  # Adjust threshold if needed\n",
    "                name = known_face_names[best_match_index]\n",
    "                color = (0, 255, 0)  # green for known faces\n",
    "\n",
    "        # Scale back up face locations since we resized the image\n",
    "        top, right, bottom, left = top * 2, right * 2, bottom * 2, left * 2\n",
    "\n",
    "        \n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "        cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Live Face Recognition\", frame)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
